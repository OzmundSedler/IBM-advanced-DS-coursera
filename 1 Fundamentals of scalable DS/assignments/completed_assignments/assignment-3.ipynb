{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Assignment 3\n\nWelcome to Assignment 3. This will be even more fun. Now we will calculate statistical measures. \n\n##\u00a0You only have to pass 4 out of 7 functions\n\nJust make sure you hit the play button on each cell from top to down. There are seven functions you have to implement. Please also make sure than on each change on a function you hit the play button again on the corresponding cell to make it available to the rest of this notebook."}, {"metadata": {}, "cell_type": "markdown", "source": "All functions can be implemented using DataFrames, ApacheSparkSQL or RDDs. We are only interested in the result. You are given the reference to the data frame in the \"df\" parameter and in case you want to use SQL just use the \"spark\" parameter which is a reference to the global SparkSession object. Finally if you want to use RDDs just use \"df.rdd\" for obtaining a reference to the underlying RDD object. But we discurage using RDD at this point in time.\n\nLet's start with the first function. Please calculate the minimal temperature for the test data set you have created. We've provided a little skeleton for you in case you want to use SQL. Everything can be implemented using SQL only if you like."}, {"metadata": {}, "cell_type": "code", "source": "def minTemperature(df,spark):\n    return df.agg({\"temperature\": \"min\"}).collect()[0][0]", "execution_count": 12, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Please now do the same for the mean of the temperature"}, {"metadata": {}, "cell_type": "code", "source": "def meanTemperature(df,spark):\n    return df.agg({\"temperature\": \"avg\"}).collect()[0][0]", "execution_count": 13, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Please now do the same for the maximum of the temperature"}, {"metadata": {}, "cell_type": "code", "source": "def maxTemperature(df,spark):\n    return df.agg({\"temperature\": \"max\"}).collect()[0][0]", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Please now do the same for the standard deviation of the temperature"}, {"metadata": {}, "cell_type": "code", "source": "from pyspark.sql.functions import mean as _mean, stddev as _stddev, col\n\ndef sdTemperature(df,spark):\n    return df.select(_stddev(col('temperature')).alias('std')).collect()[0][0]", "execution_count": 22, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Please now do the same for the skew of the temperature. Since the SQL statement for this is a bit more complicated we've provided a skeleton for you. You have to insert custom code at four positions in order to make the function work. Alternatively you can also remove everything and implement if on your own. Note that we are making use of two previously defined functions, so please make sure they are correct. Also note that we are making use of python's string formatting capabilitis where the results of the two function calls to \"meanTemperature\" and \"sdTemperature\" are inserted at the \"%s\" symbols in the SQL string."}, {"metadata": {}, "cell_type": "code", "source": "def skewTemperature(df,spark):    \n    return spark.sql(\"\"\"\nSELECT \n    (\n        1/COUNT(1)\n    ) *\n    SUM (\n        POWER((temperature - %s),3)/POWER(%s,3)\n    )\n\nAS sktemperature\nFROM washing\n\"\"\" %(meanTemperature(df,spark),sdTemperature(df,spark))).first().sktemperature", "execution_count": 30, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Kurtosis is the 4th statistical moment, so if you are smart you can make use of the code for skew which is the 3rd statistical moment. Actually only two things are different."}, {"metadata": {}, "cell_type": "code", "source": "def kurtosisTemperature(df,spark):    \n        return spark.sql(\"\"\"\nSELECT \n    (\n        1/COUNT(1)\n    ) *\n    SUM (\n        POWER(temperature-%s,4)/POWER(%s,4)\n    )\nAS ktemperature\nFROM washing\n\"\"\" %(meanTemperature(df,spark),sdTemperature(df,spark))).first().ktemperature\n", "execution_count": 32, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Just a hint. This can be solved easily using SQL as well, but as shown in the lecture also using RDDs."}, {"metadata": {}, "cell_type": "code", "source": "def correlationTemperatureHardness(df,spark):\n    return df.stat.corr(\"temperature\", \"hardness\")", "execution_count": 34, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Now it is time to grab a PARQUET file and create a dataframe out of it. Using SparkSQL you can handle it like a database. "}, {"metadata": {}, "cell_type": "code", "source": "!wget https://github.com/IBM/coursera/blob/master/coursera_ds/washing.parquet?raw=true\n!mv washing.parquet?raw=true washing.parquet", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20200105082520-0000\nKERNEL_ID = cf05f953-8dd0-45fd-88af-3c72b8e58b49\n--2020-01-05 08:25:23--  https://github.com/IBM/coursera/blob/master/coursera_ds/washing.parquet?raw=true\nResolving github.com (github.com)... 192.30.253.113\nConnecting to github.com (github.com)|192.30.253.113|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://github.com/IBM/coursera/raw/master/coursera_ds/washing.parquet [following]\n--2020-01-05 08:25:23--  https://github.com/IBM/coursera/raw/master/coursera_ds/washing.parquet\nReusing existing connection to github.com:443.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/IBM/coursera/master/coursera_ds/washing.parquet [following]\n--2020-01-05 08:25:23--  https://raw.githubusercontent.com/IBM/coursera/master/coursera_ds/washing.parquet\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.8.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.8.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 112048 (109K) [application/octet-stream]\nSaving to: 'washing.parquet?raw=true'\n\n100%[======================================>] 112,048     --.-K/s   in 0.006s  \n\n2020-01-05 08:25:23 (18.3 MB/s) - 'washing.parquet?raw=true' saved [112048/112048]\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "df = spark.read.parquet('washing.parquet')\ndf.createOrReplaceTempView('washing')\ndf.show()", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "+--------------------+--------------------+-----+--------+----------+---------+--------+-----+-----------+-------------+-------+\n|                 _id|                _rev|count|flowrate|fluidlevel|frequency|hardness|speed|temperature|           ts|voltage|\n+--------------------+--------------------+-----+--------+----------+---------+--------+-----+-----------+-------------+-------+\n|0d86485d0f88d1f9d...|1-57940679fb8a713...|    4|      11|acceptable|     null|      77| null|        100|1547808723923|   null|\n|0d86485d0f88d1f9d...|1-15ff3a0b304d789...|    2|    null|      null|     null|    null| 1046|       null|1547808729917|   null|\n|0d86485d0f88d1f9d...|1-97c2742b68c7b07...|    4|    null|      null|       71|    null| null|       null|1547808731918|    236|\n|0d86485d0f88d1f9d...|1-eefb903dbe45746...|   19|      11|acceptable|     null|      75| null|         86|1547808738999|   null|\n|0d86485d0f88d1f9d...|1-5f68b4c72813c25...|    7|    null|      null|       75|    null| null|       null|1547808740927|    235|\n|0d86485d0f88d1f9d...|1-cd4b6c57ddbe77e...|    5|    null|      null|     null|    null| 1014|       null|1547808744923|   null|\n|0d86485d0f88d1f9d...|1-a35b25b5bf43aaf...|   32|      11|acceptable|     null|      73| null|         84|1547808752028|   null|\n|0d86485d0f88d1f9d...|1-b717f7289a8476d...|   48|      11|acceptable|     null|      79| null|         84|1547808768065|   null|\n|0d86485d0f88d1f9d...|1-c2f1f8fcf178b2f...|   18|    null|      null|       73|    null| null|       null|1547808773944|    228|\n|0d86485d0f88d1f9d...|1-15033dd9eebb4a8...|   59|      11|acceptable|     null|      72| null|         96|1547808779093|   null|\n|0d86485d0f88d1f9d...|1-753dae825f9a6c2...|   62|      11|acceptable|     null|      73| null|         88|1547808782113|   null|\n|0d86485d0f88d1f9d...|1-b168089f44f03f0...|   13|    null|      null|     null|    null| 1097|       null|1547808784940|   null|\n|0d86485d0f88d1f9d...|1-403b687c6be0dea...|   23|    null|      null|       80|    null| null|       null|1547808788955|    236|\n|0d86485d0f88d1f9d...|1-195551e0455a24b...|   72|      11|acceptable|     null|      77| null|         87|1547808792134|   null|\n|0d86485d0f88d1f9d...|1-060a39fc6c2ddee...|   26|    null|      null|       62|    null| null|       null|1547808797959|    233|\n|0d86485d0f88d1f9d...|1-2234514bffee465...|   27|    null|      null|       61|    null| null|       null|1547808800960|    226|\n|0d86485d0f88d1f9d...|1-4265898bb401db0...|   82|      11|acceptable|     null|      79| null|         96|1547808802154|   null|\n|0d86485d0f88d1f9d...|1-2fbf7ca9a0425a0...|   94|      11|acceptable|     null|      73| null|         90|1547808814186|   null|\n|0d86485d0f88d1f9d...|1-203c0ee6d7fbd21...|   97|      11|acceptable|     null|      77| null|         88|1547808817190|   null|\n|0d86485d0f88d1f9d...|1-47e1965db94fcab...|  104|      11|acceptable|     null|      75| null|         80|1547808824198|   null|\n+--------------------+--------------------+-----+--------+----------+---------+--------+-----+-----------+-------------+-------+\nonly showing top 20 rows\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Now let's test the functions you've implemented"}, {"metadata": {}, "cell_type": "code", "source": "min_temperature = minTemperature(df,spark)\nprint(min_temperature)", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "80\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "mean_temperature = meanTemperature(df,spark)\nprint(mean_temperature)", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "90.03800298062593\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "max_temperature = maxTemperature(df,spark)\nprint(max_temperature)", "execution_count": 23, "outputs": [{"output_type": "stream", "text": "100\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "sd_temperature = sdTemperature(df,spark)\nprint(sd_temperature)", "execution_count": 24, "outputs": [{"output_type": "stream", "text": "6.1007610586219725\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "skew_temperature = skewTemperature(df,spark)\nprint(skew_temperature)", "execution_count": 31, "outputs": [{"output_type": "stream", "text": "0.00678066991780241\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "kurtosis_temperature = kurtosisTemperature(df,spark)\nprint(kurtosis_temperature)", "execution_count": 33, "outputs": [{"output_type": "stream", "text": "1.1564330595125916\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "correlation_temperature = correlationTemperatureHardness(df,spark)\nprint(correlation_temperature)", "execution_count": 35, "outputs": [{"output_type": "stream", "text": "0.9084547016553448\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Congratulations, you are done, please submit this notebook to the grader. \nWe have to install a little library in order to submit to coursera first.\n\nThen, please provide your email address and obtain a submission token on the grader\u2019s submission page in coursera, then execute the subsequent cells\n\n### Note: We've changed the grader in this assignment and will do so for the others soon since it gives less errors\nThis means you can directly submit your solutions from this notebook"}, {"metadata": {}, "cell_type": "code", "source": "!rm -f rklib.py\n!wget https://raw.githubusercontent.com/IBM/coursera/master/rklib.py", "execution_count": 36, "outputs": [{"output_type": "stream", "text": "--2020-01-05 08:51:31--  https://raw.githubusercontent.com/IBM/coursera/master/rklib.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.8.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.8.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2540 (2.5K) [text/plain]\nSaving to: 'rklib.py'\n\n100%[======================================>] 2,540       --.-K/s   in 0s      \n\n2020-01-05 08:51:31 (50.5 MB/s) - 'rklib.py' saved [2540/2540]\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from rklib import submitAll\nimport json\n\nkey = \"Suy4biHNEeimFQ479R3GjA\"\nemail = \"belkoviv@student.bmstu.ru\"\ntoken = \"rSDSw0sD2P7KT0yl\"\n\n\n", "execution_count": 37, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "parts_data = {}\nparts_data[\"FWMEL\"] = json.dumps(min_temperature)\nparts_data[\"3n3TK\"] = json.dumps(mean_temperature)\nparts_data[\"KD3By\"] = json.dumps(max_temperature)\nparts_data[\"06Zie\"] = json.dumps(sd_temperature)\nparts_data[\"Qc8bI\"] = json.dumps(skew_temperature)\nparts_data[\"LoqQi\"] = json.dumps(kurtosis_temperature)\nparts_data[\"ehNGV\"] = json.dumps(correlation_temperature)\n\n\n\nsubmitAll(email, token, key, parts_data)", "execution_count": 38, "outputs": [{"output_type": "stream", "text": "Submission successful, please check on the coursera grader page for the status\n-------------------------\n{\"elements\":[{\"itemId\":\"TzU1P\",\"id\":\"sUpST4RAEeawAApvKZgcCQ~TzU1P~_9DNyi-YEeqt0g6R-p81pw\",\"courseId\":\"sUpST4RAEeawAApvKZgcCQ\"}],\"paging\":{},\"linked\":{}}\n-------------------------\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python36", "display_name": "Python 3.6 with Spark", "language": "python3"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3", "version": "3.6.8", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4, "nbformat_minor": 1}